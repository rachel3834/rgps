{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1d3054-ea19-4b70-98f6-1d543bfae8ce",
   "metadata": {},
   "source": [
    "# M1 Metric Analysis\n",
    "\n",
    "The tabular results of evaluating the M1 footprint metric for the RGPS survey design and all science cases can be found in the metric_results/ directory.  The goal of this notebook is to explore those results in graphical form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9e56dd-e788-4a79-a573-432648aa2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, getcwd\n",
    "from sys import path as pythonpath\n",
    "pythonpath.append(path.join(getcwd(), '..'))\n",
    "from astropy.table import Table, Column, vstack\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import config_utils\n",
    "import regions\n",
    "import plot_metric_results\n",
    "import visualization_utils\n",
    "import numpy as np\n",
    "from astropy import units as u \n",
    "from mw_plot import MWSkyMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371fddd6-bfc9-42ba-9741-f7242592a117",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we need to load some of the configuration information for the metric simulation for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad77e1eb-787e-406c-853b-4d95b9c5c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_config = config_utils.read_config(path.join(getcwd(), '..', 'config', 'sim_config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97083664-fc98-4465-991e-3dd5b8810175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the survey regions\n",
    "all_survey_regions = regions.load_regions_from_file(sim_config, path.join(sim_config['root_dir'], 'region_data', 'rgps_survey_regions.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a74d93d-2ecf-4f20-8c68-038495c32e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wide_area',\n",
       " 'time_domain',\n",
       " 'SFR',\n",
       " 'solar_system',\n",
       " 'high_cadence',\n",
       " 'globular_clusters',\n",
       " 'molecular_clouds',\n",
       " 'AGN',\n",
       " 'open_clusters',\n",
       " 'variable_stars',\n",
       " 'galactic_center',\n",
       " 'keyholes',\n",
       " 'stellar_spectra',\n",
       " 'extinction',\n",
       " 'novae',\n",
       " 'ISM',\n",
       " 'YSO',\n",
       " 'GW']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load definitions of science cases and extract the set of topical categories\n",
    "science_cases = config_utils.read_config(path.join(getcwd(), '..', 'config', 'rgps_science_cases.json'))\n",
    "\n",
    "science_categories = []\n",
    "for author, info in science_cases.items():\n",
    "    if info['ready_for_use'] and info['category'] not in science_categories:\n",
    "        science_categories.append(info['category'])\n",
    "science_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d65097-bf11-40a1-a23a-3e71111f4732",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84ab1f4-3ba9-40d1-bfc8-d319387c5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_results(metric_results, author_list, optic_list, survey_list):\n",
    "    \"\"\"\n",
    "    Function to down-select the table of metric results by the name of the author of a science case, optic and survey design.\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "    for entry in metric_results:\n",
    "        if entry['Science_case'] in author_list \\\n",
    "            and entry['Optic'] in optic_list \\\n",
    "                and entry['Survey_strategy'] in survey_list:\n",
    "            rows.append(entry)\n",
    "            \n",
    "    sub_results = Table(rows=rows, names=metric_results.colnames)\n",
    "\n",
    "    return sub_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653db8b-610a-42cd-96b8-70f81d270dc6",
   "metadata": {},
   "source": [
    "## M1 Survey Footprint metric results \n",
    "\n",
    "The M1 metric evaluates the overlap between the survey regions requested by the different science cases and those actually included in each survey design.  Note that if a science case or strategy includes multiple regions per filter, the metric the sums the overlapping HEALpixel area for all regions.  \n",
    "\n",
    "This metric is relevant to all science cases proposed though for different reasons.  For example, the most obvious comparison to make is between the survey region and the wide-area surveys proposed.  But the time domain fields selected are also of interest.  \n",
    "\n",
    "Since including all proposals in a single graphic would make a very complex plot, the M1 metric is evaluated for the different science categories.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda75879-b74f-4e01-abe8-24760f427101",
   "metadata": {},
   "source": [
    "### Regions of interest included in the RGPS Wide-Area Survey Footprint\n",
    "\n",
    "We load the M1 results for each category of science, and plot heatmaps of the metric results for all proposals within that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508ccab5-6074-4a7b-a4be-fda5cd003eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = 'wide_area'\n",
    "metric_name = 'M1_%pix'\n",
    "metric_label = '% area of science region in survey'\n",
    "\n",
    "for category in science_categories:\n",
    "\n",
    "    m1_results_file = path.join(getcwd(), '..', 'metric_results', 'M1_survey_footprint_' + category + '_results.txt')\n",
    "    m1_results = Table.read(m1_results_file, format='ascii')\n",
    "\n",
    "    plot_file = path.join(sim_config['root_dir'], 'metric_results', 'm1_results_heatmap_' + category + '.png')\n",
    "    plot_metric_results.plot_metric_optic_heatmap(sim_config, m1_results, strategy_name, category,\n",
    "                                  metric_name, metric_label, plot_file) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e890c77-79d0-4a8c-8a62-30a089afa0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365ca1c-5e16-463b-b928-ff1d1b2612ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
