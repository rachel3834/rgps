{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a709464b-04fe-4e0b-9339-c1a707551e99",
   "metadata": {},
   "source": [
    "# Time Domain Science Cases in the Galactic Plane\n",
    "\n",
    "The purpose of this notebook is to evaluate the science cases that require time domain observations.  Here I distinguish these cases from those requesting proper motion measurements, since they tend to be distinct in their observational requirements.  For the purposes of this analysis, time domain science is identifed as those cases which requested more than 3 visits per field pointing over the lifetime of the survey.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58eb8dc6-6d81-463a-b2af-4ce114a48dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, getcwd\n",
    "from sys import path as pythonpath\n",
    "pythonpath.append(path.join(getcwd(), '..'))\n",
    "import config_utils\n",
    "import survey_footprints\n",
    "import regions\n",
    "import healpy as hp\n",
    "from mw_plot import MWSkyMap, MWSkyMapBokeh\n",
    "from astropy_healpix import HEALPix\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import Galactic, TETE, SkyCoord, ICRS\n",
    "from astropy.table import Table, Column\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import json\n",
    "from os import path\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Configure path to local repository\n",
    "root_dir = '/Users/rstreet/software/rgps'\n",
    "\n",
    "# HEALpixel grid resolution\n",
    "NSIDE = 64\n",
    "PIXAREA = hp.nside2pixarea(NSIDE, degrees=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14a520-29ee-4df6-8488-4fe477f96c82",
   "metadata": {},
   "source": [
    "First we load the simulation parameters for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c871a06-dcd5-42b9-8955-7117e5dfde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_config = config_utils.read_config(path.join(getcwd(), '..', 'config', 'sim_config.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b95a8-f60a-420f-b854-347441a7e8e6",
   "metadata": {},
   "source": [
    "The requirements of all science cases proposed as White Papers and Science Pitches are described in the configuration file for this package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61fceef5-395f-4958-b0cc-6e115b51b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_cases = config_utils.read_config(path.join(root_dir, 'config', 'rgps_science_cases.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d729c-822d-439b-9c53-a138175ca2fd",
   "metadata": {},
   "source": [
    "Science cases requesting time domain observations are identifed in the configurations with a Boolean 'time_domain' key.  \n",
    "So we can extract the information for just those cases for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f294b17-6e40-4463-b36e-9148cee745a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time domain science cases = 13\n",
      "\n",
      "\n",
      "Time domain authors and visit intervals [hrs] requested per region and filter:\n",
      "Paladini2: \n",
      "  F213 region=Paladini_TDA visit intervals=[4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0] footprint=l: [25.0, 32.0], b:[2.0, 6.0] duration=3.5 nvisits=8\n",
      "Benecchi: \n",
      "  F146 region=Benecchi1 visit intervals=[2920.0] footprint=pointing: [17.43229895, -14.63082839, 0.52] duration=730.0 nvisits=6\n",
      "Kupfer: \n",
      "  F062 region=NGC6528 visit intervals=[0.01] footprint=pointing: [56.28615068, 22.57951507, 0.433] duration=8.0 nvisits=60\n",
      "  F062 region=NGC6522 visit intervals=[0.01] footprint=pointing: [1.02461223, -3.92555662, 0.433] duration=8.0 nvisits=60\n",
      "  F062 region=VVV_CL001 visit intervals=[0.01] footprint=pointing: [5.26747512, 0.77973258, 0.433] duration=8.0 nvisits=60\n",
      "  F062 region=UKS1 visit intervals=[0.01] footprint=pointing: [268.6044167, -24.14661, 0.433] duration=8.0 nvisits=60\n",
      "  F087 region=NGC6528 visit intervals=[0.01] footprint=pointing: [56.28615068, 22.57951507, 0.433] duration=8.0 nvisits=60\n",
      "  F087 region=NGC6522 visit intervals=[0.01] footprint=pointing: [1.02461223, -3.92555662, 0.433] duration=8.0 nvisits=60\n",
      "  F087 region=VVV_CL001 visit intervals=[0.01] footprint=pointing: [5.26747512, 0.77973258, 0.433] duration=8.0 nvisits=60\n",
      "  F087 region=UKS1 visit intervals=[0.01] footprint=pointing: [268.6044167, -24.14661, 0.433] duration=8.0 nvisits=60\n",
      "Lian: \n",
      "DAmmando: \n",
      "  F184 region=DAmmando_catalog visit intervals=[3.0] footprint=catalog: table-4LAC-DR3-l.fits duration=160.0 nvisits=40\n",
      "Freeman: \n",
      "  F158 region=RRLyrae1 visit intervals=[288.0] footprint=l: [-1, 1.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "  F158 region=RRLyrae2 visit intervals=[288.0] footprint=l: [89.0, 91.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "  F158 region=RRLyrae3 visit intervals=[288.0] footprint=l: [179.0, 181.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "  F158 region=RRLyrae4 visit intervals=[288.0] footprint=l: [269.0, 271.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "  F213 region=RRLyrae1 visit intervals=[288.0] footprint=l: [-1, 1.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "  F213 region=RRLyrae2 visit intervals=[288.0] footprint=l: [89.0, 91.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "  F213 region=RRLyrae3 visit intervals=[288.0] footprint=l: [179.0, 181.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "  F213 region=RRLyrae4 visit intervals=[288.0] footprint=l: [269.0, 271.0], b:[-3.0, 3.0] duration=365.0 nvisits=30\n",
      "Navarro: \n",
      "  F106 region=ulens1 visit intervals=[1440.0] footprint=l: [-10.0, 10.0], b:[-1.0, 1.0] duration=730.0 nvisits=12\n",
      "  F129 region=ulens1 visit intervals=[1440.0] footprint=l: [-10.0, 10.0], b:[-1.0, 1.0] duration=730.0 nvisits=12\n",
      "  F158 region=ulens1 visit intervals=[1440.0] footprint=l: [-10.0, 10.0], b:[-1.0, 1.0] duration=730.0 nvisits=12\n",
      "  F213 region=ulens1 visit intervals=[1440.0] footprint=l: [-10.0, 10.0], b:[-1.0, 1.0] duration=730.0 nvisits=12\n",
      "Morihana2: \n",
      "  F129 region=CVs1 visit intervals=[0.5] footprint=pointing: [28.5, 0.0, 0.3] duration=0.21 nvisits=20\n",
      "  F129 region=CVs2 visit intervals=[0.5] footprint=l: [20.0, 50.0], b:[-3.0, 3.0] duration=5.0 nvisits=20\n",
      "  F184 region=CVs1 visit intervals=[None] footprint=pointing: [28.5, 0.0, 0.3] duration=5.0 nvisits=20\n",
      "  F184 region=CVs2 visit intervals=[None] footprint=l: [20.0, 50.0], b:[-3.0, 3.0] duration=5.0 nvisits=20\n",
      "  F213 region=CVs1 visit intervals=[None] footprint=pointing: [28.5, 0.0, 0.3] duration=5.0 nvisits=20\n",
      "  F213 region=CVs2 visit intervals=[None] footprint=l: [20.0, 50.0], b:[-3.0, 3.0] duration=5.0 nvisits=20\n",
      "Morihana1: \n",
      "  F129 region=Subaru1 visit intervals=[0.5] footprint=pointing: [28.5, 0.0, 0.3] duration=0.21 nvisits=20\n",
      "  F129 region=Subaru2 visit intervals=[0.5] footprint=l: [20.0, 50.0], b:[-3.0, 3.0] duration=0.21 nvisits=20\n",
      "  F158 region=Subaru1 visit intervals=[0.25] footprint=pointing: [28.5, 0.0, 0.3] duration=0.21 nvisits=20\n",
      "  F158 region=Subaru2 visit intervals=[0.25] footprint=l: [20.0, 50.0], b:[-3.0, 3.0] duration=730.0 nvisits=20\n",
      "  F213 region=Subaru1 visit intervals=[0.25] footprint=pointing: [28.5, 0.0, 0.3] duration=0.21 nvisits=20\n",
      "  F213 region=Subaru2 visit intervals=[0.25] footprint=l: [20.0, 50.0], b:[-3.0, 3.0] duration=0.21 nvisits=20\n",
      "Daylan: \n",
      "Bahramian: \n",
      "  F087 region=XRB1 visit intervals=[None] footprint=l: [-95.0, 103.0], b:[-13.0, 9.0] duration=730.0 nvisits=1\n",
      "  F087 region=XRB2 visit intervals=[None] footprint=l: [-115.0, 130.0], b:[-3.0, 3.0] duration=730.0 nvisits=1\n",
      "  F129 region=XRB1 visit intervals=[None] footprint=l: [-95.0, 103.0], b:[-13.0, 9.0] duration=730.0 nvisits=1\n",
      "  F129 region=XRB2 visit intervals=[None] footprint=l: [-115.0, 130.0], b:[-3.0, 3.0] duration=730.0 nvisits=1\n",
      "  F158 region=XRB1 visit intervals=[None] footprint=l: [-95.0, 103.0], b:[-13.0, 9.0] duration=730.0 nvisits=1\n",
      "  F158 region=XRB2 visit intervals=[None] footprint=l: [-115.0, 130.0], b:[-3.0, 3.0] duration=730.0 nvisits=1\n",
      "  F184 region=XRB1 visit intervals=[None] footprint=l: [-95.0, 103.0], b:[-13.0, 9.0] duration=730.0 nvisits=1\n",
      "  F184 region=XRB2 visit intervals=[None] footprint=l: [-115.0, 130.0], b:[-3.0, 3.0] duration=730.0 nvisits=1\n",
      "  F213 region=XRB1 visit intervals=[None] footprint=l: [-95.0, 103.0], b:[-13.0, 9.0] duration=730.0 nvisits=1\n",
      "  F213 region=XRB2 visit intervals=[None] footprint=l: [-115.0, 130.0], b:[-3.0, 3.0] duration=730.0 nvisits=1\n",
      "  F146 region=XRB1 visit intervals=[None] footprint=l: [-95.0, 103.0], b:[-13.0, 9.0] duration=730.0 nvisits=1\n",
      "  F146 region=XRB2 visit intervals=[None] footprint=l: [-115.0, 130.0], b:[-3.0, 3.0] duration=730.0 nvisits=1\n",
      "Rich2: \n",
      "  F184 region=Rich_TDA1 visit intervals=[8760] footprint=l: [359.544, 360.0], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "  F184 region=Rich_TDA2 visit intervals=[8760] footprint=l: [0.0, 0.344], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "  F213 region=Rich_TDA1 visit intervals=[8760] footprint=l: [359.544, 360.0], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "  F213 region=Rich_TDA2 visit intervals=[8760] footprint=l: [0.0, 0.344], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "  G150 region=Rich_TDA1 visit intervals=[8760] footprint=l: [359.544, 360.0], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "  G150 region=Rich_TDA2 visit intervals=[8760] footprint=l: [0.0, 0.344], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "  P127 region=Rich_TDA1 visit intervals=[8760] footprint=l: [359.544, 360.0], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "  P127 region=Rich_TDA2 visit intervals=[8760] footprint=l: [0.0, 0.344], b:[-0.3, 0.3] duration=730.0 nvisits=2\n",
      "Bonito: \n",
      "  F062 region=Carina visit intervals=[None] footprint=pointing: [287.60158, -0.64452, 4.0] duration=1.0 nvisits=96\n",
      "  F062 region=NGC 6611 visit intervals=[None] footprint=pointing: [16.9615, 0.8106, 1.4] duration=1.0 nvisits=96\n",
      "  F062 region=NGC 6530 visit intervals=[None] footprint=pointing: [6.08283011, -1.33133713, 0.3] duration=1.0 nvisits=96\n",
      "  F062 region=Orion Nebula Cluster visit intervals=[None] footprint=pointing: [209.01374582, -19.38160147, 1.0] duration=1.0 nvisits=96\n",
      "  F062 region=NGC 2264 visit intervals=[None] footprint=pointing: [203.09738614, 2.14137742, 1.0] duration=1.0 nvisits=96\n"
     ]
    }
   ],
   "source": [
    "time_domain_science = {author: info for author, info in science_cases.items() if info['time_domain']}\n",
    "authors_list = [x for x in time_domain_science.keys()]\n",
    "authors_list.sort()\n",
    "print('Number of time domain science cases = ' + str(len(time_domain_science)))\n",
    "print('\\n')\n",
    "print('Time domain authors and visit intervals [hrs] requested per region and filter:')\n",
    "for author, params in time_domain_science.items():\n",
    "    print(author + ': ')\n",
    "    for optic in sim_config['OPTICAL_COMPONENTS']: \n",
    "        if optic in params.keys():\n",
    "            for r in params[optic]:\n",
    "                if 'l' in r.keys(): \n",
    "                    footprint = 'l: ' + repr(r['l']) + ', b:' + repr(r['b'])\n",
    "                elif 'pointing' in r.keys():\n",
    "                    footprint = 'pointing: ' + repr(r['pointing'])\n",
    "                elif 'survey_footprint' in r.keys(): \n",
    "                    footprint = 'survey footprint: ' + r['survey_footprint'] \n",
    "                elif 'catalog' in r.keys():\n",
    "                    footprint = 'catalog: ' + r['catalog']\n",
    "                    \n",
    "                print('  ' + optic + ' region=' + r['name'] \n",
    "                      + ' visit intervals=' + repr(r['visit_interval']) \n",
    "                      + ' footprint=' + footprint\n",
    "                      + ' duration=' + repr(r['duration']) \n",
    "                      + ' nvisits=' + repr(r['nvisits'])\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417c0c4-917b-49ae-96a7-b76aa9748c68",
   "metadata": {},
   "source": [
    "Note that Rich2 was unable to give specific cadence recommendations but suggested a 15min cadence (private communication). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b1192-6943-47c7-b8bb-80272c2800d2",
   "metadata": {},
   "source": [
    "## Sky Regions for Time Domain Surveys\n",
    "\n",
    "It's informative to examine what regions of sky have been requested for time-domain surveys. To make this easier the regions for each science case have been pre-calculated, so we can load them all here, then select out those for time domain science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265dc666-f9ff-4123-9119-52bc4806721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_regions = regions.load_regions_from_file(sim_config,\n",
    "                                                         path.join(root_dir, 'config', 'rgps_time_domain_science_regions.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451b18e-2873-4d4f-840a-bda3d9511799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the regions for all time domain science cases.  Note not all of them may be present; this \n",
    "# happens if a science case is marked not ready for use.  This is done if insufficient information has been provided by \n",
    "# an author.\n",
    "time_domain_regions = {} \n",
    "for author in authors_list:\n",
    "    if author in science_regions.keys():\n",
    "        time_domain_regions[author] = science_regions[author]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e268c5-9160-4ef2-8ad7-bba108f495ca",
   "metadata": {},
   "source": [
    "In the interests of identifying regions that may have been requested by different authors for different filters, we will combine the regions across all passbands, including spectroscopic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7bc6c2-ce83-4e60-8fc4-da134fbc985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a list of regions for this optic over all science cases \n",
    "region_list = []\n",
    "region_names = []\n",
    "\n",
    "for optic in sim_config['OPTICAL_COMPONENTS']: \n",
    "\n",
    "    for author, params in time_domain_regions.items():\n",
    "        if optic in params.keys():\n",
    "\n",
    "            # Do not duplicate a region if an author has requested it for multiple filters\n",
    "            for r in params[optic]:\n",
    "                if r.name not in region_names:\n",
    "                    region_list.append(r)\n",
    "                    region_names.append(r.name)\n",
    "\n",
    "if len(region_list) > 0:\n",
    "    r_merge = regions.combine_regions(region_list)\n",
    "    r_merge.optic = 'ALL'\n",
    "    r_merge.label = 'Combined survey footprint'\n",
    "\n",
    "    mw1 = MWSkyMap(projection='aitoff', grayscale=False, grid='galactic', background='infrared', figsize=(16, 10))\n",
    "    mw1.title = r_merge.label + ' ' + r_merge.optic\n",
    "    s = r_merge.pixels_to_skycoords()\n",
    "    mw1.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c=r_merge.region_map[r_merge.pixels], cmap='Reds', s=5, alpha=0.4)\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path.join(root_dir, 'time_domain_science', 'tda_all_requested_regions_map.png'))\n",
    "\n",
    "print('Maximum HEALpixel value = ' + str(r_merge.region_map.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec405482-50f4-4b27-a24e-0b1af27f6b1d",
   "metadata": {},
   "source": [
    "## Priority regions for time domain science\n",
    "\n",
    "We can now use this heatmap to identify regions of interest to multiple science cases from the HEALpixel values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c34000-60f2-425f-93d6-91c9e446ea25",
   "metadata": {},
   "source": [
    "To identify key regions of interest, we select HEALpixels requested by multiple science cases in multiple filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de1b72-dde6-4cac-83be-9ad9a5e79e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4.0 # Minimum number of science cases requesting a HEALpixel in any filter\n",
    "\n",
    "pixels = np.where(r_merge.region_map >= threshold)[0]\n",
    "\n",
    "candidate_regions = {'pixel_set': pixels}\n",
    "\n",
    "area = len(pixels) * PIXAREA\n",
    "print('N overlap science cases=' + str(int(threshold)) \n",
    "      + ' N HEALpixels=' + str(len(pixels)) + ' area=' + str(round(area,2)) + 'sq.deg.')\n",
    "\n",
    "# Plot these regions \n",
    "mw1 = MWSkyMap(projection='aitoff', grayscale=False, grid='galactic', background='infrared', figsize=(16, 10))\n",
    "mw1.title = 'Overlap of science regions'\n",
    "proj = HEALPix(nside=64, order='ring', frame='icrs')\n",
    "\n",
    "s = proj.healpix_to_skycoord(pixels)\n",
    "mw1.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c='r', s=5, alpha=1.0)\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path.join(root_dir, 'time_domain_science', 'all_tda_overlap_region_map_all_passbands.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9274a1e-3f4e-48c0-b6cb-6d74ac6e282c",
   "metadata": {},
   "source": [
    "The candidate_regions entries per optic may have multiple clusters of HEALpixels, which need to be counted as separate regions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24004f40-6825-4866-8693-20bf682833aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrange(llist):\n",
    "\n",
    "    idx1 = np.where(llist > 180.0)[0] \n",
    "    idx2 = np.where(llist <= 180.0)[0] \n",
    "\n",
    "    l0 = llist[idx1].min() \n",
    "    l1 = llist[idx2].max() \n",
    "\n",
    "    return l0, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721e19b-3b6c-4562-b433-3f819cf5c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_pixels(params):\n",
    "    \n",
    "    # Convert the HEALpixels to a set of Skycoords in the galactic frame\n",
    "    proj = HEALPix(nside=64, order='ring', frame='icrs')\n",
    "    pixels = params['pixel_set']\n",
    "    coords = proj.healpix_to_skycoord(pixels)\n",
    "    coords = coords.transform_to('galactic')\n",
    "\n",
    "    clusters = {}\n",
    "    nc = -1\n",
    "    max_sep = 2.5 * u.deg\n",
    "    while len(coords) > 0:\n",
    "        s = coords[0]\n",
    "        \n",
    "        sep = s.separation(coords)\n",
    "\n",
    "        jdx = np.where(sep <= max_sep)[0]\n",
    "        kdx = np.where(sep > max_sep)[0]\n",
    "        \n",
    "        l = coords[jdx].l.deg\n",
    "        lmin = l.min() \n",
    "        lmax = l.max()\n",
    "        print('RANGE: ',l, coords[jdx].b.deg)\n",
    "        \n",
    "        # Handle case if the region straddles the l-coordinate rollover\n",
    "        if lmin > 0.0 and lmin < 180.0 and lmax > 180.0: \n",
    "            l0,l1 = get_lrange(l)\n",
    "        else:\n",
    "            l0 = l.min()\n",
    "            l1 = l.max() \n",
    "        b0 = coords[jdx].b.deg.min()\n",
    "        b1 = coords[jdx].b.deg.max()\n",
    "        print('CORNERS: ', lmin, lmax, l0, l1, b0, b1)\n",
    "        \n",
    "        # Calculate the centroid as the mid-point of the diagonal between \n",
    "        # the opposing corners of a box encompasing the all HEALpixels in the region\n",
    "        corner1 = SkyCoord(l0, b0, frame='galactic', unit=(u.deg, u.deg))\n",
    "        corner2 = SkyCoord(l1, b1, frame='galactic', unit=(u.deg, u.deg))\n",
    "        pa = corner1.position_angle(corner2)\n",
    "        sep = corner1.separation(corner2)\n",
    "        center = corner1.directional_offset_by(pa, sep/2)  \n",
    "        \n",
    "        cluster = { \n",
    "            'l_center': center.l.deg,\n",
    "            'b_center': center.b.deg,\n",
    "            'l0': l0,\n",
    "            'l1': l1,\n",
    "            'b0': b0,\n",
    "            'b1': b1,\n",
    "            'pixels': pixels[jdx]\n",
    "        }\n",
    "        nc += 1 \n",
    "        \n",
    "        clusters[nc] = cluster\n",
    "\n",
    "        # Remove identified pixels from the coords list \n",
    "        coords = coords[kdx]\n",
    "        pixels = pixels[kdx]\n",
    "        \n",
    "    params['clusters'] = clusters\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370987d-ca6e-4016-ba3d-594c86bea8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_set = {}\n",
    "params = cluster_pixels(candidate_regions)\n",
    "\n",
    "# Filter out clusters that are unfeasibly large\n",
    "for key, value in params.items():\n",
    "    if key == 'clusters':\n",
    "        subset = {}\n",
    "        for cid,cluster in params['clusters'].items():\n",
    "            #dl = abs(cluster['l0'] - cluster['l1'])\n",
    "            #if len(cluster['pixels']) < 20.0 and dl < 20.0:\n",
    "            print(' -> ', cid, cluster)\n",
    "            subset[cid] = cluster\n",
    "        params['clusters'] = subset\n",
    "    else:\n",
    "        print(key, value)\n",
    "    \n",
    "candidate_regions = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b2aa5-046f-43e8-ac27-772b449b0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel clusters are separated by assuming they have to be a maximum angular separation apart\n",
    "max_sep = 2.5*u.deg\n",
    "optic_col = []\n",
    "data = np.array([])\n",
    "ids = []\n",
    "centroids = np.array([])\n",
    "for cid,cluster in candidate_regions['clusters'].items():\n",
    "    s = SkyCoord(cluster['l_center'], cluster['b_center'], frame='galactic', unit=(u.deg, u.deg))\n",
    "\n",
    "    # Check whether we already have a region at this location \n",
    "    if len(centroids) > 0: \n",
    "        cluster_centroids = SkyCoord(centroids[:,0], centroids[:,1], frame='galactic', unit=(u.deg, u.deg))\n",
    "        sep = s.separation(cluster_centroids) \n",
    "        \n",
    "        # If not, then add a new cluster\n",
    "        if (sep >= max_sep).all():                \n",
    "            ids.append(len(ids))\n",
    "            data = np.vstack((data,[\n",
    "                cluster['l_center'], cluster['b_center'], \n",
    "                cluster['l0'], cluster['l1'], cluster['b0'], cluster['b1']\n",
    "            ]))\n",
    "\n",
    "            optic_col.append(optic)\n",
    "\n",
    "            centroids = np.vstack((centroids, [cluster['l_center'], cluster['b_center']]))\n",
    "            \n",
    "        # If the cluster is already known, compare the boundaries and extend if need be to  \n",
    "        # form the cluster superset of pixels.  Also add the optic to the list of optics requesting \n",
    "        # this cluster\n",
    "        else:\n",
    "            #print('Existing clusters: ', cluster_centroids)\n",
    "            #print('Candiddate cluster ',s)\n",
    "            \n",
    "            #print('Separations: ',sep, max_sep)\n",
    "            \n",
    "            cid = np.where(sep <= max_sep)[0][0]\n",
    "            if len(data.shape) == 1: \n",
    "                cmatch = data\n",
    "            else:\n",
    "                cmatch = data[cid,:]\n",
    "            superset = False \n",
    "            if superset:\n",
    "                cmatch[2] = min(cmatch[2], cluster['l0']) \n",
    "                cmatch[3] = max(cmatch[3], cluster['l1']) \n",
    "                cmatch[4] = min(cmatch[4], cluster['b0']) \n",
    "                cmatch[5] = max(cmatch[5], cluster['b1'])\n",
    "                cmatch[0] = np.median([cmatch[2],cmatch[3]])\n",
    "                cmatch[1] = np.median([cmatch[4],cmatch[5]])\n",
    "                if len(data.shape) == 1:\n",
    "                    data = cmatch\n",
    "                else:\n",
    "                    data[cid,:] = cmatch\n",
    "            if optic not in optic_col[cid]:\n",
    "                optic_col[cid] = optic_col[cid] + ', ' + optic\n",
    "            \n",
    "    # If we have no clusters yet, simply add a new one \n",
    "    else:\n",
    "        ids.append(len(ids))\n",
    "        data = np.array([\n",
    "            cluster['l_center'], cluster['b_center'], \n",
    "            cluster['l0'], cluster['l1'], cluster['b0'], cluster['b1']\n",
    "        ])\n",
    "        optic_col.append(optic)\n",
    "\n",
    "        centroids = np.array([[cluster['l_center'], cluster['b_center']]])\n",
    "                \n",
    "data = np.array(data)\n",
    "\n",
    "# Allow for testing with a single filter\n",
    "if len(data.shape) == 1:\n",
    "    TD_regions = Table([\n",
    "        Column(name='ID', data=ids),\n",
    "        Column(name='l_center', data=[data[0]]),\n",
    "        Column(name='b_center', data=[data[1]]),\n",
    "        Column(name='l0', data=[data[2]]),\n",
    "        Column(name='l1', data=[data[3]]),\n",
    "        Column(name='b0', data=[data[4]]),\n",
    "        Column(name='b1', data=[data[5]])\n",
    "    ])\n",
    "\n",
    "else:\n",
    "    TD_regions = Table([\n",
    "        Column(name='ID', data=ids),\n",
    "        Column(name='l_center', data=data[:,0]),\n",
    "        Column(name='b_center', data=data[:,1]),\n",
    "        Column(name='l0', data=data[:,2]),\n",
    "        Column(name='l1', data=data[:,3]),\n",
    "        Column(name='b0', data=data[:,4]),\n",
    "        Column(name='b1', data=data[:,5])\n",
    "    ])\n",
    "\n",
    "TD_regions.pprint_all()\n",
    "\n",
    "TD_regions.write(path.join(root_dir, 'time_domain_science', 'all_tda_candidate_tda_fields_table.txt'), format='ascii', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163e2af-703d-45b8-8a14-3c85fe779ffa",
   "metadata": {},
   "source": [
    "Plot these selected regions for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39218d76-0aec-48de-8529-b6c6fc8cce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outline(skymapplot, survey_region, ssmall=5.0, outline_color='red'):\n",
    "    \"\"\"\n",
    "    Function to plot the outline of a survey footprint, given the survey region boundaries in the form of \n",
    "    survey_region = { 'l': [lmin, lmax], 'b': [bmin, bmax] }\n",
    "    \"\"\"\n",
    "\n",
    "    l0 = survey_region['l'][0]\n",
    "    l1 = survey_region['l'][1]\n",
    "    if l0 > 0.0 and l0 > 180.0 and l1 < 180.0: \n",
    "        lrangeset = [np.arange(l0, 359.9, 0.1), np.arange(0.0, l1, 0.1)]\n",
    "        brangeset = [\n",
    "            np.arange(survey_region['b'][0], survey_region['b'][1], 0.1), \n",
    "            np.arange(survey_region['b'][0], survey_region['b'][1], 0.1), \n",
    "        ]\n",
    "    else:\n",
    "        lrangeset = [np.arange(l0, l1, 0.1)]\n",
    "        brangeset = [np.arange(survey_region['b'][0], survey_region['b'][1], 0.1)]\n",
    "    \n",
    "    # Plot a boundary region if lrange or brange has non-zero length: \n",
    "    for xx in range(0, len(lrangeset), 1): \n",
    "        lrange = lrangeset[xx]\n",
    "        brange = brangeset[xx]\n",
    "        \n",
    "        if len(lrange) > 0 and len(brange) > 0:\n",
    "            # Since the plotting package supports only scatter plots, calculate a range of points \n",
    "            # to represent the outer boundaries.  \n",
    "            llist = []\n",
    "            blist = []\n",
    "        \n",
    "            # Right-hand edge of box\n",
    "            llist += [survey_region['l'][0]]*len(brange)\n",
    "            blist += brange.tolist()\n",
    "        \n",
    "            # Left-hand edge of box \n",
    "            llist += [survey_region['l'][1]]*len(brange)\n",
    "            blist += brange.tolist()\n",
    "        \n",
    "            # Lower edge of box \n",
    "            llist += lrange.tolist()\n",
    "            blist += [survey_region['b'][0]]*len(lrange)\n",
    "        \n",
    "            # Upper edge of box \n",
    "            llist += lrange.tolist()\n",
    "            blist += [survey_region['b'][1]]*len(lrange)\n",
    "    \n",
    "            alpha = 0.4\n",
    "            \n",
    "        # Otherwise, this is a single-point region, so plot it as such\n",
    "        else:\n",
    "            llist = [survey_region['l'][0]]\n",
    "            blist = [survey_region['b'][0]]\n",
    "            alpha = 1.0\n",
    "            \n",
    "        # Add this outline to the plot; this has to be done in ICRS coordinates\n",
    "        s = SkyCoord(llist, blist, frame='galactic', unit=(u.deg, u.deg))\n",
    "        s = s.transform_to(ICRS)\n",
    "        skymapplot.scatter(s.ra.deg*u.deg, s.dec.deg*u.deg, c=outline_color, s=ssmall, alpha=alpha)\n",
    "\n",
    "    return skymapplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0241e6c-0dad-4584-a60b-ca359e844b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the selected TDA regions \n",
    "mw2 = MWSkyMap(projection='aitoff', grayscale=False, grid='galactic', background='infrared', figsize=(16, 10))\n",
    "mw2.title = 'Candidate time domain survey fields'\n",
    "proj = HEALPix(nside=64, order='ring', frame='icrs')\n",
    "\n",
    "for r in TD_regions:\n",
    "    outline = {\n",
    "        'l': [float(r['l0']), float(r['l1'])],\n",
    "        'b': [float(r['b0']), float(r['b1'])]\n",
    "    }\n",
    "    #print(outline)\n",
    "    plot_outline(mw2, outline)\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path.join(root_dir, 'time_domain_science', 'all_tda_candidate_tda_fields.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8447e6d-e65b-4efd-8e6a-ecff1e2fa3d2",
   "metadata": {},
   "source": [
    "## Refining the Time Domain Regions \n",
    "\n",
    "A number of these science cases request very wide regions (e.g. most of the Galactic Plane), essentially indicating that anywhere within the footprint would be beneficial for time domain observations.  The analysis above shows that including these regions tends to result in a larger number of smaller regions where some large catalog entries (e.g. the AGN catalog) overlap with a very wide area footprint.  While this individual object is no doubt of interest, it causes the algorithm to simply re-create the footprint of the catalog, rather than select regions of interest to multiple science cases.  \n",
    "\n",
    "A better approach is not to include these very-large area regions in the list of cases for building the regions themselves.  NOTE: THIS DOES NOT MEAN EXCLUDED REGIONS ARE IGNORED!  Instead we evaluate the the overlap for those science cases from the regions chosen later on when the metrics are calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca90d67-d78f-4e13-a5f2-72ea3e481a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_list = ['DAmmando', 'Pascucci', 'Bahramian', 'Navarro']\n",
    "time_domain_authors = []\n",
    "for author in authors_list: \n",
    "    if author not in pop_list: \n",
    "        time_domain_authors.append(author)\n",
    "\n",
    "time_domain_regions = {} \n",
    "for author in time_domain_authors:\n",
    "    if author in science_regions.keys():\n",
    "        time_domain_regions[author] = science_regions[author]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3f5db-6200-40fc-973b-6b9dff5d454f",
   "metadata": {},
   "source": [
    "We can now repeat the above analysis with this revised list of science cases as a basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f12ae7-bb06-4434-9725-20c835c830d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a list of regions for this optic over all science cases \n",
    "region_list = []\n",
    "region_names = []\n",
    "\n",
    "for optic in sim_config['OPTICAL_COMPONENTS']: \n",
    "\n",
    "    for author, params in time_domain_regions.items():\n",
    "        if optic in params.keys():\n",
    "\n",
    "            # Do not duplicate a region if an author has requested it for multiple filters\n",
    "            for r in params[optic]:\n",
    "                if r.name not in region_names:\n",
    "                    region_list.append(r)\n",
    "                    region_names.append(r.name)\n",
    "\n",
    "if len(region_list) > 0:\n",
    "    r_merge = regions.combine_regions(region_list)\n",
    "    r_merge.optic = 'selected TDA science cases'\n",
    "    r_merge.label = 'Combined survey footprint'\n",
    "\n",
    "    mw1 = MWSkyMap(projection='aitoff', grayscale=False, grid='galactic', background='infrared', figsize=(16, 10))\n",
    "    mw1.title = r_merge.label + ' ' + r_merge.optic\n",
    "    s = r_merge.pixels_to_skycoords()\n",
    "    mw1.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c=r_merge.region_map[r_merge.pixels], cmap='Reds', s=5, alpha=0.4)\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path.join(root_dir, 'time_domain_science', 'tda_selected_requested_regions_map.png'))\n",
    "\n",
    "print('Maximum HEALpixel value = ' + str(r_merge.region_map.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0d57b-f8fc-4509-86ad-6584ee536fb6",
   "metadata": {},
   "source": [
    "Select the regions prioritized by multiple science cases - note revised selection threshold since there are now fewer science cases per HEALpixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ad699-59cb-471b-8395-2576e67eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3.0 # Minimum number of science cases requesting a HEALpixel in any filter\n",
    "\n",
    "pixels = np.where(r_merge.region_map >= threshold)[0]\n",
    "\n",
    "candidate_regions = {'pixel_set': pixels}\n",
    "\n",
    "area = len(pixels) * PIXAREA\n",
    "print('N overlap science cases=' + str(int(threshold)) \n",
    "      + ' N HEALpixels=' + str(len(pixels)) + ' area=' + str(round(area,2)) + 'sq.deg.')\n",
    "\n",
    "# Plot these regions \n",
    "mw1 = MWSkyMap(projection='aitoff', grayscale=False, grid='galactic', background='infrared', figsize=(16, 10))\n",
    "mw1.title = 'Overlap of science regions'\n",
    "proj = HEALPix(nside=64, order='ring', frame='icrs')\n",
    "\n",
    "s = proj.healpix_to_skycoord(pixels)\n",
    "mw1.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c='r', s=5, alpha=1.0)\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path.join(root_dir, 'time_domain_science', 'selected_tda_overlap_region_map_all_passbands.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9578de1-f586-4b16-92dd-3d7e2780727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_set = {}\n",
    "params = cluster_pixels(candidate_regions)\n",
    "\n",
    "# Filter out clusters that are unfeasibly large\n",
    "for key, value in params.items():\n",
    "    if key == 'clusters':\n",
    "        subset = {}\n",
    "        for cid,cluster in params['clusters'].items():\n",
    "            #dl = abs(cluster['l0'] - cluster['l1'])\n",
    "            #if len(cluster['pixels']) < 20.0 and dl < 20.0:\n",
    "            print(' -> ', cid, cluster)\n",
    "            subset[cid] = cluster\n",
    "        params['clusters'] = subset\n",
    "    else:\n",
    "        print(key, value)\n",
    "    \n",
    "candidate_regions = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9c8eb-7957-4bff-971b-d4bbfa3d4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel clusters are separated by assuming they have to be a maximum angular separation apart\n",
    "max_sep = 1.0*u.deg\n",
    "optic_col = []\n",
    "data = np.array([])\n",
    "ids = []\n",
    "centroids = np.array([])\n",
    "for cid,cluster in candidate_regions['clusters'].items():\n",
    "    s = SkyCoord(cluster['l_center'], cluster['b_center'], frame='galactic', unit=(u.deg, u.deg))\n",
    "\n",
    "    # Check whether we already have a region at this location \n",
    "    if len(centroids) > 0: \n",
    "        cluster_centroids = SkyCoord(centroids[:,0], centroids[:,1], frame='galactic', unit=(u.deg, u.deg))\n",
    "        sep = s.separation(cluster_centroids) \n",
    "        \n",
    "        # If not, then add a new cluster\n",
    "        if (sep >= max_sep).all():                \n",
    "            ids.append(len(ids))\n",
    "            data = np.vstack((data,[\n",
    "                cluster['l_center'], cluster['b_center'], \n",
    "                cluster['l0'], cluster['l1'], cluster['b0'], cluster['b1']\n",
    "            ]))\n",
    "\n",
    "            optic_col.append(optic)\n",
    "\n",
    "            centroids = np.vstack((centroids, [cluster['l_center'], cluster['b_center']]))\n",
    "            \n",
    "        # If the cluster is already known, compare the boundaries and extend if need be to  \n",
    "        # form the cluster superset of pixels.  Also add the optic to the list of optics requesting \n",
    "        # this cluster\n",
    "        else:\n",
    "            #print('Existing clusters: ', cluster_centroids)\n",
    "            #print('Candiddate cluster ',s)\n",
    "            \n",
    "            #print('Separations: ',sep, max_sep)\n",
    "            \n",
    "            cid = np.where(sep <= max_sep)[0][0]\n",
    "            if len(data.shape) == 1: \n",
    "                cmatch = data\n",
    "            else:\n",
    "                cmatch = data[cid,:]\n",
    "            superset = False \n",
    "            if superset:\n",
    "                cmatch[2] = min(cmatch[2], cluster['l0']) \n",
    "                cmatch[3] = max(cmatch[3], cluster['l1']) \n",
    "                cmatch[4] = min(cmatch[4], cluster['b0']) \n",
    "                cmatch[5] = max(cmatch[5], cluster['b1'])\n",
    "                cmatch[0] = np.median([cmatch[2],cmatch[3]])\n",
    "                cmatch[1] = np.median([cmatch[4],cmatch[5]])\n",
    "                if len(data.shape) == 1:\n",
    "                    data = cmatch\n",
    "                else:\n",
    "                    data[cid,:] = cmatch\n",
    "            if optic not in optic_col[cid]:\n",
    "                optic_col[cid] = optic_col[cid] + ', ' + optic\n",
    "            \n",
    "    # If we have no clusters yet, simply add a new one \n",
    "    else:\n",
    "        ids.append(len(ids))\n",
    "        data = np.array([\n",
    "            cluster['l_center'], cluster['b_center'], \n",
    "            cluster['l0'], cluster['l1'], cluster['b0'], cluster['b1']\n",
    "        ])\n",
    "        optic_col.append(optic)\n",
    "\n",
    "        centroids = np.array([[cluster['l_center'], cluster['b_center']]])\n",
    "                \n",
    "data = np.array(data)\n",
    "\n",
    "# Allow for testing with a single filter\n",
    "if len(data.shape) == 1:\n",
    "    TD_regions = Table([\n",
    "        Column(name='ID', data=ids),\n",
    "        Column(name='l_center', data=[data[0]]),\n",
    "        Column(name='b_center', data=[data[1]]),\n",
    "        Column(name='l0', data=[data[2]]),\n",
    "        Column(name='l1', data=[data[3]]),\n",
    "        Column(name='b0', data=[data[4]]),\n",
    "        Column(name='b1', data=[data[5]])\n",
    "    ])\n",
    "\n",
    "else:\n",
    "    TD_regions = Table([\n",
    "        Column(name='ID', data=ids),\n",
    "        Column(name='l_center', data=data[:,0]),\n",
    "        Column(name='b_center', data=data[:,1]),\n",
    "        Column(name='l0', data=data[:,2]),\n",
    "        Column(name='l1', data=data[:,3]),\n",
    "        Column(name='b0', data=data[:,4]),\n",
    "        Column(name='b1', data=data[:,5])\n",
    "    ])\n",
    "\n",
    "TD_regions.pprint_all()\n",
    "\n",
    "TD_regions.write(path.join(root_dir, 'time_domain_science', 'selected_tda_candidate_tda_fields_table.txt'), format='ascii', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549ea9d-7917-429b-ac4f-33a825523ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the selected TDA regions \n",
    "mw2 = MWSkyMap(grayscale=False, grid='galactic', background='infrared', figsize=(16, 10), \n",
    "               center=(0.0*u.deg, 0.0*u.deg), radius=(60.0*u.deg, 60.0*u.deg))\n",
    "\n",
    "mw2.title = 'Candidate time domain survey fields'\n",
    "proj = HEALPix(nside=64, order='ring', frame='icrs')\n",
    "\n",
    "for r in TD_regions:\n",
    "    outline = {\n",
    "        'l': [float(r['l0']), float(r['l1'])],\n",
    "        'b': [float(r['b0']), float(r['b1'])]\n",
    "    }\n",
    "    #print(outline)\n",
    "    plot_outline(mw2, outline)\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path.join(root_dir, 'time_domain_science', 'selected_tda_candidate_tda_fields.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589aacf-3f8c-49f8-a07f-7b80e652808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close up of Galactic Center Field\n",
    "l_cen = 0.0\n",
    "b_cen = 0.0\n",
    "\n",
    "r = TD_regions[5]\n",
    "\n",
    "mw3 = MWSkyMap(grayscale=False, grid='galactic', background='infrared', figsize=(16, 10), \n",
    "               center=(l_cen*u.deg, b_cen*u.deg), radius=(10.0*u.deg, 10.0*u.deg))\n",
    "mw3.title = 'Time domain field ' + str(r['ID']) \n",
    "\n",
    "# Plot shaded HEALpixel map of requested regions\n",
    "s = r_merge.pixels_to_skycoords()\n",
    "mw3.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c=r_merge.region_map[r_merge.pixels], cmap='Reds', s=150, alpha=0.8)\n",
    "\n",
    "# Plot outlines of time domain fields\n",
    "outline = {\n",
    "    'l': [float(r['l0']), float(r['l1'])],\n",
    "    'b': [float(r['b0']), float(r['b1'])]\n",
    "}\n",
    "plot_outline(mw3, outline)\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654601b-7223-4bc1-9af9-5bc85a38ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refined boundaries for W40/Serpens region\n",
    "serpens = [\n",
    "    {\n",
    "        'l': [24.416209200921237, 31.8769619838468],\n",
    "        'b': [1.4651381451102967, 3.6]\n",
    "    },\n",
    "    {\n",
    "        'l': [26.9820729303582, 29.108464857799547],\n",
    "        'b': [-0.4766073328462903, 1.4651381451102967]\n",
    "    },\n",
    "#    {\n",
    "#        'l': [27.624388519213877, 28.47723108449249],\n",
    "#        'b': [-0.4766073328462903, 0.42073947105053183]\n",
    "#    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18957f5-a2ce-41a1-8a04-bd4da729db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W40\n",
    "wforty = SkyCoord('18:31:29', '−02:05:24', frame='icrs', unit=(u.hourangle, u.deg)) \n",
    "wforty_gal = wforty.transform_to('galactic')\n",
    "wforty_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6360940-6cb1-4bd3-bda0-3b7f4a077abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close up of W40/Serpens\n",
    "l_cen = -30.0\n",
    "b_cen = 0.0\n",
    "\n",
    "mw3 = MWSkyMap(grayscale=False, grid='galactic', background='infrared', figsize=(16, 10), \n",
    "               center=(l_cen*u.deg, b_cen*u.deg), radius=(10.0*u.deg, 10.0*u.deg))\n",
    "mw3.title = 'Time domain field: W40/Serpens'\n",
    "\n",
    "# Plot shaded HEALpixel map of requested regions\n",
    "s = r_merge.pixels_to_skycoords()\n",
    "mw3.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c=r_merge.region_map[r_merge.pixels], cmap='Reds', s=150, alpha=0.8)\n",
    "\n",
    "# Plot outlines of time domain fields\n",
    "for i in range(1,5,1):\n",
    "    r = TD_regions[i]\n",
    "    outline = {\n",
    "        'l': [float(r['l0']), float(r['l1'])],\n",
    "        'b': [float(r['b0']), float(r['b1'])]\n",
    "    }\n",
    "    plot_outline(mw3, outline)\n",
    "\n",
    "# Plot refined boundary\n",
    "for outline in serpens:\n",
    "    plot_outline(mw3, outline, outline_color='yellow')\n",
    "\n",
    "# Plot location of W40 \n",
    "mw3.scatter(wforty.ra.deg * u.deg, wforty.dec.deg * u.deg, c='purple', s=100, alpha=0.8)\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.tight_layout()\n",
    "plt.savefig(path.join(root_dir, 'time_domain_science', 'W40_Serpens_field_NIR.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a3bbc3-c0c7-4b3c-aed6-b66937b32955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close up of W40/Serpens\n",
    "l_cen = -30.0\n",
    "b_cen = 0.0\n",
    "\n",
    "mw3 = MWSkyMap(grayscale=False, grid='galactic', background='optical', figsize=(16, 10), \n",
    "               center=(l_cen*u.deg, b_cen*u.deg), radius=(10.0*u.deg, 10.0*u.deg))\n",
    "mw3.title = 'Time domain field: W40/Serpens'\n",
    "\n",
    "# Plot shaded HEALpixel map of requested regions\n",
    "s = r_merge.pixels_to_skycoords()\n",
    "mw3.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c=r_merge.region_map[r_merge.pixels], cmap='Reds', s=150, alpha=0.8)\n",
    "\n",
    "# Plot outlines of time domain fields\n",
    "for i in range(1,5,1):\n",
    "    r = TD_regions[i]\n",
    "    outline = {\n",
    "        'l': [float(r['l0']), float(r['l1'])],\n",
    "        'b': [float(r['b0']), float(r['b1'])]\n",
    "    }\n",
    "    plot_outline(mw3, outline)\n",
    "\n",
    "# Plot refined boundary\n",
    "for outline in serpens:\n",
    "    plot_outline(mw3, outline, outline_color='yellow')\n",
    "\n",
    "# Plot location of W40 \n",
    "mw3.scatter(wforty.ra.deg * u.deg, wforty.dec.deg * u.deg, c='purple', s=100, alpha=0.8)\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.tight_layout()\n",
    "plt.savefig(path.join(root_dir, 'time_domain_science', 'W40_Serpens_field_optical.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1f4de-f9ac-4d12-b8e2-86e611e323fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cen = -48.0\n",
    "b_cen = 0.0\n",
    "\n",
    "r = TD_regions[0]\n",
    "\n",
    "mw3 = MWSkyMap(grayscale=False, grid='galactic', background='infrared', figsize=(16, 10), \n",
    "               center=(l_cen*u.deg, b_cen*u.deg), radius=(10.0*u.deg, 10.0*u.deg))\n",
    "mw3.title = 'Time domain field ' + str(r['ID']) \n",
    "\n",
    "# Plot shaded HEALpixel map of requested regions\n",
    "s = r_merge.pixels_to_skycoords()\n",
    "mw3.scatter(s.ra.deg * u.deg, s.dec.deg * u.deg, c=r_merge.region_map[r_merge.pixels], cmap='Reds', s=150, alpha=0.8)\n",
    "\n",
    "# Plot outlines of time domain fields\n",
    "outline = {\n",
    "    'l': [float(r['l0']), float(r['l1'])],\n",
    "    'b': [float(r['b0']), float(r['b1'])]\n",
    "}\n",
    "plot_outline(mw3, outline)\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a179f2f-c236-4154-a4d5-bb3bb702c806",
   "metadata": {},
   "source": [
    "## Science from each Time Domain Region \n",
    "\n",
    "It is valuable now to check what science can be done within which TDA region.  This is most easily done by generating CelestialRegions for the selected fields, since these have HEALpixel maps which can be compared directly with those of the science cases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a13778-543c-4932-b3de-8450d0e9df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tda_survey = {} \n",
    "\n",
    "for row in TD_regions:\n",
    "\n",
    "    # Need to catch region boxes that extend over l=360/0deg and split them into two regions if they \n",
    "    # straddle the boundary\n",
    "    if row['l0'] > 180.0 and row['l0'] > row['l1']:\n",
    "        params = {\n",
    "            \"F213\": [\n",
    "                { # Nominal filter used to fit required structure\n",
    "                \"l\": [row['l0'], 359.9],\n",
    "                \"b\": [row['b0'], row['b1']],\n",
    "                \"nvisits\": 1,\n",
    "                \"duration\": 730.0,\n",
    "                \"visit_interval\": [None],\n",
    "                \"name\": str(row['ID'])\n",
    "                },\n",
    "                { \n",
    "                \"l\": [0.0, row['l1']],\n",
    "                \"b\": [row['b0'], row['b1']],\n",
    "                \"nvisits\": 1,\n",
    "                \"duration\": 730.0,\n",
    "                \"visit_interval\": [None],\n",
    "                \"name\": str(row['ID'])\n",
    "                },\n",
    "            ],\n",
    "            \"comment\": \"None\",\n",
    "            \"ready_for_use\": \"True\"\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        params = {\n",
    "            \"F213\": [{ # Nominal filter used to fit required structure\n",
    "                \"l\": [row['l0'], row['l1']],\n",
    "                \"b\": [row['b0'], row['b1']],\n",
    "                \"nvisits\": 1,\n",
    "                \"duration\": 730.0,\n",
    "                \"visit_interval\": [None],\n",
    "                \"name\": str(row['ID'])\n",
    "                }],\n",
    "            \"comment\": \"None\",\n",
    "            \"ready_for_use\": \"True\"\n",
    "        }\n",
    "    tda_survey[str(row['ID'])] = params\n",
    "\n",
    "tda_region_set = regions.build_region_maps(sim_config, tda_survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b296b4-73ab-4e2e-b8f0-64d798b4a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_per_tda_field = {key: {'cases': [], 'filters': [], 'visit_interval': []} for key in tda_region_set.keys()}\n",
    "\n",
    "for author, science_params in time_domain_regions.items():\n",
    "\n",
    "    # Make a list of all regions for this science case in all filters\n",
    "    science_region_list = []\n",
    "    for optic in sim_config['OPTICAL_COMPONENTS']:\n",
    "        if len(science_params[optic]) > 0:\n",
    "            science_region_list += science_params[optic]\n",
    "    \n",
    "    for survey_id,params in tda_region_set.items():\n",
    "        overlap = False\n",
    "        \n",
    "        for r1 in params['F213']:\n",
    "            for r2 in science_region_list:\n",
    "                idx = set(r1.pixels).intersection(set(r2.pixels))\n",
    "                if len(idx) > 0 and not overlap: \n",
    "                    overlap = True\n",
    "                    science_per_tda_field[survey_id]['cases'].append(author)\n",
    "                    science_per_tda_field[survey_id]['filters'] += [rr.optic for rr in science_region_list]\n",
    "                    for rr in science_region_list:\n",
    "                        if not np.isnan(rr.visit_interval[0]):\n",
    "                            entries = [str(f) for f in rr.visit_interval.tolist()]\n",
    "                            science_per_tda_field[survey_id]['visit_interval'] += entries\n",
    "\n",
    "for field_id, params in science_per_tda_field.items():\n",
    "    print('TDA region ' + str(field_id) + ' supports science case(s) ' + ','.join(params['cases']))\n",
    "    print(' -> Filterset ' + ','.join(params['filters']))\n",
    "    if len(params['visit_interval']) > 0:\n",
    "        print(' -> Visit intervals ' + ','.join(params['visit_interval']))\n",
    "    else:\n",
    "        print(' -> No visit intervals defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bce8ba-bfe0-4d17-a9eb-80d3514ee392",
   "metadata": {},
   "source": [
    "Just as importantly, what science cases were not included in the selected regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0159a-e731-4813-a413-5a23efb9d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for author, science_params in time_domain_regions.items():\n",
    "    in_region = False\n",
    "    for field_id, params in science_per_tda_field.items():\n",
    "        if author in params['cases']:\n",
    "            in_region = True \n",
    "\n",
    "    if not in_region:\n",
    "        print('Regions requested by ' + author + ' are not included in any region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7118f0-5549-471e-8219-748113806662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
